\section{Semantic Score}
\textbf{Q2}: To what level is DocTide able to produce function-level documentation comparable to that of a human developer?
\\ \\
The intend behind developing DocTide as a LLM-based autonomous agent, is to automate the task of creating function-level documentation to a level comparable to that of a human developer. Therefor to evaluate the level at which DocTide manages to do this, our evaluation protocol collects pairs of comments generated by DocTide and their 'real world' human created counterparts. We then use the Python module Sentence Transformers\footnote{\url{https://www.sbert.net/examples/cross_encoder/applications/README.html}} to calculate the semantic similarity through running a Cross Encoder model.

Taking into considerations the efficiency of running this model over large quantities of comment pairs, we have decided to use the \textit{'stsb-roberta-base'} model, which scores 90.17 in the STSbenchmark\footnote{\url{https://sbert.net/docs/cross_encoder/pretrained_models.html}}.

\subsection{Data handling}
Identifying what qualifies as a "good" score. - Probably using quantiles and manual sampling.

\subsection{Results}
\subsection{Discussion of result}

